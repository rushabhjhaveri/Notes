# Amazon S3 Introduction # 

## S3 Overview ## 

Amazon S3 is one of the main building blocks of AWS 

Advertised as "infinitely scaling" storage 

Many websites use S3 as a backbone 

Many AWS services use S3 as an integration as well 

### S3 - Buckets ### 

S3 allows for the storage of objects [files] in "buckets" [directories] 

Buckets must have a globally unique name [across all regions all accounts] 

Buckets are defined at the region level 

S3 looks like a global service but buckets are created in a region 

Naming convention: 
* no uppercase, no underscore 
* 3-63 characters long 
* not an IP 
* must start with a lowercase letter or number 
* must not start with the prefix xn-- 
* must not end with the suffix -s3alias 

### S3 - Objects ### 

Objects [files] have a Key 

The key is the full path 
* s3://my-bucket/my_file.txt 

The key is composed of prefix + object name 

There is no concept of directories within buckets 

Just keys with very long names that contain slashes 

Object values are the content of the body 

Max object size is 5TB 

If uploading more than 5 GB, must use multi-part upload 

Metadata [list of text key/value pairs - system or user metadata] 

Tags [unicode key/value pair - up to ten] - useful for security/lifecycle 

Version ID [if versioning is enabled] 

## S3 Security - Bucket Policy ## 

User-based: IAM Policies - which API calls should be allowed for a specific user from IAM 

Resource-Based: 
* Bucket Policies - bucket-wide rules from the S3 console - allows cross-account access 
* Object Access Control List [ACL] - finer-gran [can be disabled] 
* Bucket ACL - less common [can be disabled] 

Note: an IAM principal can access an S3 object if the user's IAM permissions allow it or the resource policy allows it AND there's no explicit deny 

Encyption: encrypt objects in S3 using encryption keys 

### S3 Bucket Policies ### 

JSON-based policies 

Resources: buckets and objects 

Effect: allow/deny 

Actions: set of API to allow/deny 

Principal: the account or user to apply the policy to 

Use S3 bucket for policy to grant public access to the bucket, and to force objects to be encrypted at upload 

## S3 Website Overview ## 

S3 can host statis websites and have them accessible on the internet 

The website URL will depend on the region: 
* http://bucket-name.s3-website-aws-region.amazonaws.com, OR, 
* http://bucket-name.s3-website.aws-region.amazonaws.com 

If receiving a 403 Forbidden error, make sure bucket policy allows public reads 

## S3 Versioning ## 

Can version files in S3 

Enabled at the bucket level 

Same key overwrite will change the "version" 

It is best practice to version buckets 
* Protects against unintended deletes [ability to restore a version] 
* Easily rollback to a previous version 

Any file not versioned prior to versioning will have a version "null" 

Suspending versioning does not delete previous versions 

## S3 Replication ## 

Must enable versioning in source and destination buckets 

Cross-Region Replication [CRR] 

Same-Region Replication [SRR] 

Buckets can be in different AWS accounts 

Copying is asynchronous 

Must give proper IAM permissions to S3 

Use cases for CRR: compliance, lower-latency access, replication across accounts 

Use cases for SRR: log aggregation live replication between production and test accounts 

After enabling replication, only new objects get replicated 

Optionally, can replicate existing objects using S3 Batch Replication [replaces existing objects and objects that failed replication] 

For DELETE operations, 
* Can replicate delete markers from source to target [optional setting] 
* Deletions with a version ID are not replicated [to avoid malicious deletes] 

There is no "chaining" of replication 
* If bucket 1 has replication into bucket 2 which has replication into bucket 3 
* Then objects created in bucket 1 are not replicated to bucket 3 

## S3 Storage Classes Overview ## 

### S3 Dirability and Availability ### 

Durability: 
* Measures how often an object will be lost 
* High durability [11 9's] of objects across multiple AZ 
* Same for all storage classes 

Availability: 
* Measures how readily available a service is 
* Varies depending on storage class 

### S3 Standard - General Purpose ### 

99.99% availability 

Used for frequently accessed data 

Low latency and high throughput 

Sustain two concurrent facility failures 

Use cases: big data analytics; mobile/gaming applications; content distribution 

### S3 Storage Class - Infrequent Access ### 

For data that is less frequently accessed, but requires rapid access when needed 

Lower cost than S3 standard 

S3 Standard - Infrequent Access 
* 99.9% availability 
* Use cases: disaster recovery, backups 

Amazon S3 One Zone - Infrequent Access 
* High durability [11 9's] in a single AZ; data lost when AZ is destroyed 
* 99.5% availability 
* Use cases: storing secondary backup copies of on-premise data; data that can be recreated 

### S3 Glacier Storage Classes ### 

Low-cost object storage meant for archiving/backup 

Pricing: price for storage + object retrieval cost 

S3 Glacier Instant Retrieval: 
* Millisecond retrieval, great for data accessed once a quarter 
* Minimum storage duration of 90 days 

S3 Glacier Flexible Retrieval 
* Expedited [one to five minutes], Standard [three to five hours], Bulk [five to twelve hours] - free 
* Minimum storage duration of 90 days 

S3 Glacier Deep Archive 
* For long-term storage 
* Standard [12 hours], Bulk [48 hours] 
* Minimum storage duration of 180 days 

### S3 Intelligent-Tiering ### 

Small monthly monitoring and auto-tiering fee 

Moves objects automatically between access tiers based on usage 

No retrieval charges 

Frequent access tier [automatic]: default tier 

Infrequent access tier [automatic]: objects not accessed for 30 days 

Archive instant access tier [automatic]: objects not accessed for 90 days 

Archive access tier [optional]: objects not accessed for 90 - 700+ days 

Deep archive access tier [optional]: objects not accessed for 180 - 700+ days 